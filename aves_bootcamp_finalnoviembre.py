# -*- coding: utf-8 -*-
"""Aves Bootcamp .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nU8vUY6k0CSKDkHc_qYFv07rfvjOL6M2

# **Clusterización de Aves en Calarcá: Ubicación y Estacionalidad Migratoria**

**Integrantes:**
* Linamaría Martínez
* David Santiago Blandón
* José Weisz
* Francisco Javier Pineda

**Bootcamp: Inteligencia Artificial
Nivel Explorador**


6 de septiembre de 2025

# **Librerías y Dataset**
"""

# Importamos librerías
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.api as sm
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier
import folium
from IPython.display import display
import plotly.express as px
from datetime import datetime

# Dataset importado desde drive
from google.colab import drive
drive.mount('/content/drive')

#Crear DataFrame
import pandas as pd
ruta = '/content/drive/MyDrive/Proyecto-Final-IA/DATOS-AVES-QUINDIO.txt'
df = pd.read_csv(ruta, sep='\t')

"""# **Limpieza y Exploración Básica de Datos**"""

#1. Exploración Inicial y Limpieza

# Carga y exploración inicialdel conjunto de datos
print("=== EXPLORACIÓN INICIAL ===")
print(f"Dimensiones del dataset: {df.shape}")
print("\nInformación del dataset:")
print(df.info())
print("\nEstadísticas descriptivas:")
print(df.describe())
print("\nValores nulos por columna:")
print(df.isnull().sum())

# Limpieza de datos
print("\n=== LIMPIEZA DE DATOS ===")

#Seleccionando columnas a Utilizar
df_reducido=df[['species','family','individualCount','year','month','locality','basisOfRecord','recordedBy','decimalLatitude','decimalLongitude']]
df_reducido

#Examinar DataFrame
df_reducido.describe()
df_reducido.info()

#Eliminar Nulos, DataFrame Final
df_final=df_reducido.dropna()
df_final.info()
df_final

"""# **Normalización de datos**"""

# Convertir año y mes a enteros
df_final['year'] = df_final['year'].astype(int)
df_final['month'] = df_final['month'].astype(int)

# Revisar los datos de 'Represa Cameguadua' en la columna 'locality'
represa_cameguadua = df[df['locality'] == 'Represa Cameguadua']
represa_cameguadua
df_final

#Eliminar localidad NO perteneciente
# Verificar si existe la localidad "Represa Cameguadua" en el DataFrame
print("=== VERIFICACIÓN DE LOCALIDAD 'REPRESA CAMEGUADUA' ===")

# Buscar variaciones del nombre (por si hay diferencias en mayúsculas, espacios, etc.)
localidades_unicas = df_final['locality'].unique()
cameguadua_variaciones = [loc for loc in localidades_unicas if 'cameguadua' in loc.lower()]

print("Variaciones de 'Cameguadua' encontradas:")
for loc in cameguadua_variaciones:
    print(f"- {loc}")
    print(f"  Número de registros: {len(df_final[df_final['locality'] == loc])}")
    # Eliminar registros de Represa Cameguadua y sus variaciones
print("\n=== ELIMINANDO REGISTROS DE REPRESA CAMEGUADUA ===")

# Crear una copia del DataFrame original por si necesitas revertir los cambios
df_final_original = df_final.copy()

# Contar registros antes de eliminar
registros_antes = len(df_final)
print(f"Registros antes de eliminar: {registros_antes}")

# Eliminar todas las variaciones de Cameguadua
df_final = df_final[~df_final['locality'].str.lower().str.contains('cameguadua')]

# Contar registros después de eliminar
registros_despues = len(df_final)
registros_eliminados = registros_antes - registros_despues

print(f"Registros después de eliminar: {registros_despues}")
print(f"Registros eliminados: {registros_eliminados}")

# Verificar que ya no existen registros de Cameguadua
cameguadua_despues = df_final[df_final['locality'].str.lower().str.contains('cameguadua')]
print(f"Registros de Cameguadua después de la eliminación: {len(cameguadua_despues)}")

# Ver todas las columnas de df y filtrar por búsqueda exacta en 'locality'
pd.set_option('display.max_columns', None)
display(df_final[df_final['locality'].str.contains('Represa Cameguadua', na=False)])

# Diccionario de mapeo para estandarizar las localidades
mapeo_localidades = {
    'ecoparque peñas blancas': 'Ecoparque Peñas Blancas',
    'ecoparque peñas blancas': 'Ecoparque Peñas Blancas',
    # Agrega aquí más variaciones y su forma correcta
}
# Función para estandarizar las localidades
def estandarizar_localidad(localidad):
    if isinstance(localidad, str): # Verifica si el valor es un string
        localidad_lower = localidad.lower().strip()  # Convertir a minúsculas y quitar espacios
        return mapeo_localidades.get(localidad_lower, localidad)  # Retorna el nombre corregido o el original si no está en el mapeo
    else:
        return localidad # Retorna noReturn non-string values as they are

# Aplicar la función a la columna 'locality' in df_final
df_final.loc[:, 'locality'] = df_final['locality'].apply(estandarizar_localidad)

# Verificar los cambios
print(df_final.columns.tolist())

df_final[ 'locality' ]

"""#**Análisis Exploratorio**"""

# 1. EXPLORACIÓN INICIAL Y ANÁLISIS ESTADÍSTICO
print("=== ANÁLISIS EXPLORATORIO DE DATOS (EDA) ===")
print("="*50)

# a. Distribución de frecuencias para variables categóricas
print("\n1. DISTRIBUCIÓN DE FRECUENCIAS PARA VARIABLES CATEGÓRICAS")
print("-" * 60)

# Especies más comunes
print("\nTop 10 especies más frecuentes:")
top_especies = df_final['species'].value_counts().head(10)
print(top_especies)

# Familias más comunes
print("\nTop 10 familias más frecuentes:")
top_familias = df_final['family'].value_counts().head(10)
print(top_familias)

# Localidades más comunes
print("\nTop 10 localidades más frecuentes:")
top_localidades = df_final['locality'].value_counts().head(10)
print(top_localidades)

# Observadores más activos
print("\nTop 10 observadores más activos:")
top_observadores = df_final['recordedBy'].value_counts().head(10)
print(top_observadores)

# b. Medidas de tendencia central y variabilidad para variables numéricas
print("\n\n2. MEDIDAS DE TENDENCIA CENTRAL Y VARIABILIDAD")
print("-" * 60)

# Función para calcular y mostrar estadísticas descriptivas
def analizar_variable_numerica(data, columna):
    print(f"\n--- Análisis de '{columna}' ---")

    # Medidas de tendencia central
    media = data[columna].mean()
    mediana = data[columna].median()
    moda = data[columna].mode().iloc[0] if not data[columna].mode().empty else "No hay moda única"

    # Medidas de variabilidad
    desviacion_std = data[columna].std()
    varianza = data[columna].var()
    rango = data[columna].max() - data[columna].min()
    q1 = data[columna].quantile(0.25)
    q3 = data[columna].quantile(0.75)
    rango_iqr = q3 - q1

    # Mostrar resultados
    print(f"Medidas de tendencia central:")
    print(f"  Media: {media:.2f}")
    print(f"  Mediana: {mediana:.2f}")
    print(f"  Moda: {moda}")

    print(f"\nMedidas de variabilidad:")
    print(f"  Desviación estándar: {desviacion_std:.2f}")
    print(f"  Varianza: {varianza:.2f}")
    print(f"  Rango: {rango:.2f}")
    print(f"  Rango intercuartílico (IQR): {rango_iqr:.2f}")
    print(f"  Quartil 1 (Q1): {q1:.2f}")
    print(f"  Quartil 3 (Q3): {q3:.2f}")

    # Detección de valores atípicos
    limite_inferior = q1 - 1.5 * rango_iqr
    limite_superior = q3 + 1.5 * rango_iqr
    valores_atipicos = data[(data[columna] < limite_inferior) | (data[columna] > limite_superior)]

    print(f"\nValores atípicos:")
    print(f"  Límite inferior: {limite_inferior:.2f}")
    print(f"  Límite superior: {limite_superior:.2f}")
    print(f"  Número de valores atípicos: {len(valores_atipicos)}")
    print(f"  Porcentaje de valores atípicos: {len(valores_atipicos)/len(data)*100:.2f}%")

    return {
        'media': media,
        'mediana': mediana,
        'moda': moda,
        'desviacion_std': desviacion_std,
        'varianza': varianza,
        'rango': rango,
        'rango_iqr': rango_iqr,
        'valores_atipicos': len(valores_atipicos)
    }

# Analizar variables numéricas
variables_numericas = ['individualCount', 'year', 'month', 'decimalLatitude', 'decimalLongitude']
estadisticas = {}

for variable in variables_numericas:
    estadisticas[variable] = analizar_variable_numerica(df_final, variable)

# c. Visualizaciones
print("\n\n3. VISUALIZACIONES")
print("-" * 60)

# Configurar el estilo de las gráficas
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# Crear subplots para las distribuciones principales
fig, axes = plt.subplots(3, 2, figsize=(15, 15))
fig.suptitle('Análisis Exploratorio de Datos - Distribuciones y Variabilidad', fontsize=16, fontweight='bold')

# 1. Distribución de conteo individual
sns.histplot(df_final['individualCount'], bins=30, kde=True, ax=axes[0, 0])
axes[0, 0].axvline(estadisticas['individualCount']['media'], color='red', linestyle='--', label=f'Media: {estadisticas["individualCount"]["media"]:.2f}')
axes[0, 0].axvline(estadisticas['individualCount']['mediana'], color='green', linestyle='--', label=f'Mediana: {estadisticas["individualCount"]["mediana"]:.2f}')
axes[0, 0].axvline(estadisticas['individualCount']['moda'], color='blue', linestyle='--', label=f'Moda: {estadisticas["individualCount"]["moda"]:.2f}')
axes[0, 0].set_title('Distribución de Conteo Individual con Medidas de Tendencia Central')
axes[0, 0].set_xlabel('Número de Individuos')
axes[0, 0].set_ylabel('Frecuencia')
axes[0, 0].legend()

# 2. Distribución por años
sns.histplot(df_final['year'], bins=len(df_final['year'].unique()), kde=True, ax=axes[0, 1])
axes[0, 1].axvline(estadisticas['year']['media'], color='red', linestyle='--', label=f'Media: {estadisticas["year"]["media"]:.2f}')
axes[0, 1].axvline(estadisticas['year']['mediana'], color='green', linestyle='--', label=f'Mediana: {estadisticas["year"]["mediana"]:.2f}')
axes[0, 1].axvline(estadisticas['year']['moda'], color='blue', linestyle='--', label=f'Moda: {estadisticas["year"]["moda"]:.2f}')
axes[0, 1].set_title('Distribución por Años con Medidas de Tendencia Central')
axes[0, 1].set_xlabel('Año')
axes[0, 1].set_ylabel('Frecuencia')
axes[0, 1].legend()

# 3. Distribución por meses
sns.histplot(df_final['month'], bins=12, kde=True, ax=axes[1, 0])
axes[1, 0].axvline(estadisticas['month']['media'], color='red', linestyle='--', label=f'Media: {estadisticas["month"]["media"]:.2f}')
axes[1, 0].axvline(estadisticas['month']['mediana'], color='green', linestyle='--', label=f'Mediana: {estadisticas["month"]["mediana"]:.2f}')
axes[1, 0].axvline(estadisticas['month']['moda'], color='blue', linestyle='--', label=f'Moda: {estadisticas["month"]["moda"]:.2f}')
axes[1, 0].set_title('Distribución por Meses con Medidas de Tendencia Central')
axes[1, 0].set_xlabel('Mes')
axes[1, 0].set_ylabel('Frecuencia')
axes[1, 0].legend()

# 4. Boxplot de conteo individual
sns.boxplot(y=df_final['individualCount'], ax=axes[1, 1])
axes[1, 1].axhline(estadisticas['individualCount']['media'], color='red', linestyle='--', label=f'Media: {estadisticas["individualCount"]["media"]:.2f}')
axes[1, 1].axhline(estadisticas['individualCount']['mediana'], color='green', linestyle='--', label=f'Mediana: {estadisticas["individualCount"]["mediana"]:.2f}')
axes[1, 1].set_title('Boxplot - Conteo Individual con Medidas de Tendencia Central')
axes[1, 1].set_ylabel('Número de Individuos')
axes[1, 1].legend()

# 5. Top 10 especies
top_especies.plot(kind='bar', ax=axes[2, 0])
axes[2, 0].set_title('Top 10 Especies Más Frecuentes')
axes[2, 0].set_xlabel('Especies')
axes[2, 0].set_ylabel('Frecuencia')
axes[2, 0].tick_params(axis='x', rotation=90)

# 6. Top 10 localidades
top_localidades.plot(kind='bar', ax=axes[2, 1])
axes[2, 1].set_title('Top 10 Localidades Más Frecuentes')
axes[2, 1].set_xlabel('Localidades')
axes[2, 1].set_ylabel('Frecuencia')
axes[2, 1].tick_params(axis='x', rotation=90)

plt.tight_layout()
plt.show()

# d. Gráficas adicionales para medidas de tendencia central y variabilidad
print("\n4. GRÁFICAS ADICIONALES DE MEDIDAS DE TENDENCIA CENTRAL")
print("-" * 60)

# Crear gráficas específicas para medidas de tendencia central
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('Medidas de Tendencia Central y Variabilidad', fontsize=16, fontweight='bold')

# 1. Comparación de media, mediana y moda para todas las variables
variables = list(estadisticas.keys())
medias = [estadisticas[var]['media'] for var in variables]
medianas = [estadisticas[var]['mediana'] for var in variables]
modas = [estadisticas[var]['moda'] for var in variables]

x_pos = np.arange(len(variables))
width = 0.25

axes[0, 0].bar(x_pos - width, medias, width, label='Media', color='red', alpha=0.7)
axes[0, 0].bar(x_pos, medianas, width, label='Mediana', color='green', alpha=0.7)
axes[0, 0].bar(x_pos + width, modas, width, label='Moda', color='blue', alpha=0.7)
axes[0, 0].set_xlabel('Variables')
axes[0, 0].set_ylabel('Valores')
axes[0, 0].set_title('Comparación de Media, Mediana y Moda por Variable')
axes[0, 0].set_xticks(x_pos)
axes[0, 0].set_xticklabels(variables, rotation=90)
axes[0, 0].legend()

# 2. Desviación estándar por variable
desviaciones = [estadisticas[var]['desviacion_std'] for var in variables]
axes[0, 1].bar(variables, desviaciones, color='orange', alpha=0.7)
axes[0, 1].set_xlabel('Variables')
axes[0, 1].set_ylabel('Desviación Estándar')
axes[0, 1].set_title('Desviación Estándar por Variable')
axes[0, 1].tick_params(axis='x', rotation=90)

# 3. Rango intercuartílico por variable
rangos_iqr = [estadisticas[var]['rango_iqr'] for var in variables]
axes[1, 0].bar(variables, rangos_iqr, color='purple', alpha=0.7)
axes[1, 0].set_xlabel('Variables')
axes[1, 0].set_ylabel('Rango Intercuartílico (IQR)')
axes[1, 0].set_title('Rango Intercuartílico por Variable')
axes[1, 0].tick_params(axis='x', rotation=90)

# 4. Porcentaje de valores atípicos por variable
porcentajes_atipicos = [estadisticas[var]['valores_atipicos']/len(df_final)*100 for var in variables]
axes[1, 1].bar(variables, porcentajes_atipicos, color='red', alpha=0.7)
axes[1, 1].set_xlabel('Variables')
axes[1, 1].set_ylabel('Porcentaje de Valores Atípicos (%)')
axes[1, 1].set_title('Porcentaje de Valores Atípicos por Variable')
axes[1, 1].tick_params(axis='x', rotation=90)

plt.tight_layout()
plt.show()

# e. Matriz de correlación (para variables numéricas)
print("\n5. MATRIZ DE CORRELACIÓN")
print("-" * 60)

# Calcular matriz de correlación
correlation_matrix = df_final[variables_numericas].corr()

# Visualizar matriz de correlación
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
            square=True, linewidths=0.5, cbar_kws={"shrink": .8})
plt.title('Matriz de Correlación - Variables Numéricas')
plt.tight_layout()
plt.show()

# f. Resumen estadístico completo
print("\n6. RESUMEN ESTADÍSTICO COMPLETO")
print("-" * 60)
print(df_final[variables_numericas].describe())

# g. Análisis de valores faltantes (aunque ya los eliminamos, es bueno verificarlo)
print("\n7. ANÁLISIS DE VALORES FALTANTES")
print("-" * 60)
print("Valores nulos por columna:")
print(df_final.isnull().sum())

print("\n" + "="*50)
print("FIN DEL ANÁLISIS EXPLORATORIO DE DATOS")
print("="*50)

"""# **Análisis Univariado**"""

# 2. Análisis de localidades con más registros en Calarcá
print("\n=== EXPLORACIÓN DE DATOS ===")
print("\n=== TOP 10 LOCALIDADES EN CALARCÁ ===")
top_localidades = df_final['locality'].value_counts().head(10)
display(top_localidades)

# Visualización
plt.figure(figsize=(12, 8))
top_localidades.plot(kind='barh', color='teal')
plt.title('Top 10 Localidades con Más Registros en Calarcá')
plt.xlabel('Número de Registros')
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Obtener el top 10 de especies más registradas por cantidad de filas (no necesariamente suma de individuos)
top_especies = df_final['species'].value_counts().head(10).index

# Filtrar el dataset para esas especies
df_top10 = df_final[df_final['species'].isin(top_especies)]

# Agrupar por especie y año sumando el individualCount
variacion_top10_anio = df_top10.groupby(['species', 'year'])['individualCount'].sum().unstack(fill_value=0)

# Graficar la variación anual de registros por especie
plt.figure(figsize=(13,6))
for especie in variacion_top10_anio.index:
    plt.plot(variacion_top10_anio.columns, variacion_top10_anio.loc[especie], marker='o', label=especie)

plt.title('Variación anual de registros para Top 10 especies más registradas')
plt.xlabel('Año')
plt.ylabel('Cantidad observada (individualCount)')
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))
plt.grid(True)
plt.tight_layout()
plt.show()

df_final.head(1)

# 3. Análisis de observadores (quien lo ha hecho)
print("\n=== TOP 10 OBSERVADORES EN CALARCÁ ===")
top_observadores = df_final['recordedBy'].value_counts().head(10)
display(top_observadores)

# 4. Análisis de especies más y menos registradas
print("\n=== ESPECIES MÁS REGISTRADAS EN CALARCÁ (TOP 10) ===")
top_especies = df_final['species'].value_counts().head(10)
display(top_especies)

print("\n=== ESPECIES MENOS REGISTRADAS EN CALARCÁ (TOP 10) ===")
especies_con_registros = df_final['species'].value_counts()
menos_especies = especies_con_registros[especies_con_registros >= 1].tail(10)
display(menos_especies)

#4b Registros Anuales
sns.countplot(data=df_final, x='year')
plt.xticks(rotation=45)
plt.show()

#4b Localidades con mas registros
# Obtener las 10 localidades con más registros
top_localities = df_final['locality'].value_counts().head(10)

# Crear la visualización
plt.figure(figsize=(12, 8))
bars = plt.barh(top_localities.index, top_localities.values, color='skyblue')

# Visualización
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

top_especies.plot(kind='bar', ax=ax1, color='green')
ax1.set_title('Top 10 Especies Más Registradas en Calarcá')
ax1.tick_params(axis='x', rotation=45)

menos_especies.plot(kind='bar', ax=ax2, color='orange')
ax2.set_title('Top 10 Especies Menos Registradas en Calarcá (con solo 1 registro)')
ax2.tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

import pandas as pd
# 5. Análisis temporal por temporadas de migración
def definir_temporada(mes):
    if mes in [9, 10, 11, 12, 1, 2, 3, 4]:
        return 'Migracion Boreal'
    else:
        return 'Migracion Austral'

df_final.loc[:, 'temporada'] = df_final['month'].apply(definir_temporada)

# Análisis por temporada
registros_por_temporada = df_final['temporada'].value_counts()
especies_por_temporada = df_final.groupby('temporada')['species'].nunique()

print("\n=== REGISTROS POR TEMPORADA DE MIGRACIÓN ===")
print(registros_por_temporada)

print("\n=== ESPECIES ÚNICAS POR TEMPORADA DE MIGRACIÓN ===")
print(especies_por_temporada)

# Visualización
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

registros_por_temporada.plot(kind='bar', ax=ax1, color=['skyblue', 'lightcoral'])
ax1.set_title('Registros por Temporada de Migración')
ax1.set_ylabel('Número de Registros')

especies_por_temporada.plot(kind='bar', ax=ax2, color=['lightgreen', 'gold'])
ax2.set_title('Especies Únicas por Temporada de Migración')
ax2.set_ylabel('Número de Especies')

plt.tight_layout()
plt.show()

# 6. Análisis de las 10 especies más comunes por temporada
top_10_especies = top_especies.index.tolist()
df_top_especies = df_final[df_final['species'].isin(top_10_especies)]

especies_por_temporada = pd.crosstab(df_top_especies['temporada'], df_top_especies['species'])
print("\n=== DISTRIBUCIÓN DE TOP 10 ESPECIES POR TEMPORADA ===")
print(especies_por_temporada)

# Visualización
especies_por_temporada.plot(kind='bar', figsize=(14, 7))
plt.title('Distribución de las 10 Especies Más Comunes por Temporada de Migración')
plt.ylabel('Número de Registros')
plt.xticks(rotation=0)
plt.legend(title='Especies', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# 7. Análisis de tendencias temporales
print("\n=== TENDENCIAS TEMPORALES ===")
registros_por_anio = df_final.groupby('year').size()
diversidad_por_anio = df_final.groupby('year')['species'].nunique()

# Modelo de tendencia para registros
X = registros_por_anio.index.values.reshape(-1, 1)
y = registros_por_anio.values

modelo_registros = LinearRegression()
modelo_registros.fit(X, y)
tendencia_registros = modelo_registros.predict(X)

# Visualización
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))

ax1.plot(registros_por_anio.index, registros_por_anio.values, 'o-', label='Registros')
ax1.plot(registros_por_anio.index, tendencia_registros, 'r--', label='Tendencia')
ax1.set_title('Evolución del Número de Registros por Año en Calarcá')
ax1.set_xlabel('Año')
ax1.set_ylabel('Número de Registros')
ax1.legend()

ax2.plot(diversidad_por_anio.index, diversidad_por_anio.values, 'o-', color='green')
ax2.set_title('Evolución de la Diversidad de Especies por Año en Calarcá')
ax2.set_xlabel('Año')
ax2.set_ylabel('Número de Especies Únicas')

plt.tight_layout()
plt.show()

"""# **Análisis de Distribución Espacial**"""

# 8. Análisis de distribución espacial
print("\n=== DISTRIBUCIÓN ESPACIAL ===")

# Crear mapa de registros
mapa_calarca = folium.Map(location=[4.53, -75.64], zoom_start=13)

# Agregar puntos al mapa
for idx, row in df_final.iterrows():
    popup_text = f"{row['species']}<br>{row['locality']}<br>{row['year']}-{row['month']}"
    folium.CircleMarker(
        location=[row['decimalLatitude'], row['decimalLongitude']],
        radius=5,
        popup=popup_text,
        color='green',
        fill=True,
        fillColor='white',
        fillOpacity=0.6
    ).add_to(mapa_calarca)

# Mostrar el mapa
print("Mapa de registros de aves en Calarcá:")
display(mapa_calarca)

"""# **Clusterización**"""

# 9. Identificación de clusters espaciales
coordenadas = df_final[['decimalLatitude', 'decimalLongitude']].values

# Determinar número óptimo de clusters usando el método del codo
print("=== MÉTODO DEL CODO PARA DETERMINAR NÚMERO ÓPTIMO DE CLUSTERS ===")

# Calcular la suma de cuadrados dentro de los clusters (inercia) para diferentes valores de k
inercias = []
valores_k = range(1, 11)  # Probamos de 1 a 10 clusters

for k in valores_k:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(coordenadas)
    inercias.append(kmeans.inertia_)

# Graficar el método del codo
plt.figure(figsize=(10, 6))
plt.plot(valores_k, inercias, 'bo-')
plt.xlabel('Número de clusters (k)')
plt.ylabel('Inercia (Suma de cuadrados intra-cluster)')
plt.title('Método del Codo para Determinar Número Óptimo de Clusters')
plt.xticks(valores_k)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# 9. Identificación de clusters espaciales
coordenadas = df_final[['decimalLatitude', 'decimalLongitude']].values

# Aplicar K-Means para encontrar clusters
kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
df_final['cluster'] = kmeans.fit_predict(coordenadas)

# Visualizar clusters en el mapa
mapa_clusters = folium.Map(location=[4.53, -75.64], zoom_start=13)
colores = ['red', 'blue', 'green', 'purple']

for idx, row in df_final.iterrows():
    folium.CircleMarker(
        location=[row['decimalLatitude'], row['decimalLongitude']],
        radius=5,
        popup=f"Cluster: {row['cluster']}",
        color=colores[row['cluster']],
        fill=True,
        fillColor=colores[row['cluster']],
        fillOpacity=0.6
    ).add_to(mapa_clusters)

print("Mapa de clusters de registros en Calarcá:")
display(mapa_clusters)

# 10. Análisis de especies por cluster
print("\n=== DISTRIBUCIÓN DE ESPECIES POR CLUSTER ===")
especies_por_cluster = pd.crosstab(df_final['cluster'], df_final['species'])
top_especies_por_cluster = especies_por_cluster.apply(lambda x: x.nlargest(5).index.tolist(), axis=1)

for cluster, especies in top_especies_por_cluster.items():
    print(f"Cluster {cluster}: {', '.join(especies)}")

# Análisis de lo que hay en cada cluster
print("=== CARACTERÍSTICAS DE CADA CLUSTER ===")

for cluster_id in sorted(df_final['cluster'].unique()):
    cluster_data = df_final[df_final['cluster'] == cluster_id]

    print(f"\n--- Cluster {cluster_id} ---")
    print(f"Número de registros: {len(cluster_data)}")
    print(f"Localidades principales: {cluster_data['locality'].value_counts().head(3).to_dict()}")
    print(f"Especies más comunes: {cluster_data['species'].value_counts().head(3).to_dict()}")

    # Coordenadas promedio del cluster
    avg_lat = cluster_data['decimalLatitude'].mean()
    avg_lon = cluster_data['decimalLongitude'].mean()
    print(f"Ubicación promedio: Lat {avg_lat:.4f}, Lon {avg_lon:.4f}")

print("\n=== MAPA ALTERNATIVO: COLORES POR DIVERSIDAD DE ESPECIES ===")

# Calcular diversidad de especies por cluster
diversidad_por_cluster = df_final.groupby('cluster')['species'].nunique()

# Asignar colores según la diversidad
colores_por_diversidad = {}
for cluster_id in diversidad_por_cluster.index:
    # Normalizar la diversidad (0-1)
    diversidad_normalizada = diversidad_por_cluster[cluster_id] / diversidad_por_cluster.max()

    # Asignar color (más diversidad = color más "verde")
    if diversidad_normalizada > 0.7:
        colores_por_diversidad[cluster_id] = 'green'
    elif diversidad_normalizada > 0.4:
        colores_por_diversidad[cluster_id] = 'blue'
    else:
        colores_por_diversidad[cluster_id] = 'yellow'

# Crear mapa con colores basados en diversidad
mapa_diversidad = folium.Map(location=[4.53, -75.64], zoom_start=13)

for idx, row in df_final.iterrows():
    folium.CircleMarker(
        location=[row['decimalLatitude'], row['decimalLongitude']],
        radius=5,
        popup=f"Cluster: {row['cluster']}<br>Especie: {row['species']}<br>Localidad: {row['locality']}",
        color=colores_por_diversidad[row['cluster']],
        fill=True,
        fillColor=colores_por_diversidad[row['cluster']],
        fillOpacity=0.6
    ).add_to(mapa_diversidad)

# Añadir leyenda
legend_html = '''
<div style="position: fixed; bottom: 50px; left: 50px; width: 150px; height: 90px;
            background-color: white; border:2px solid grey; z-index:9999; font-size:14px;
            padding: 10px;">
    <b>Diversidad de Especies</b><br>
    <i style="background: darkgreen; width: 20px; height: 20px; display: inline-block;"></i> Alta<br>
    <i style="background: blue; width: 20px; height: 20px; display: inline-block;"></i> Media<br>
    <i style="background: yellow; width: 20px; height: 20px; display: inline-block;"></i> Baja
</div>
'''
mapa_diversidad.get_root().html.add_child(folium.Element(legend_html))

print("Mapa de clusters con colores según diversidad de especies:")
display(mapa_diversidad)

# Mapa interactivo con puntos de alta diversidad

# Filtrar ubicaciones con más de 100 especies únicas
diversidad_por_ubicacion = df_final.groupby(['decimalLongitude', 'decimalLatitude'])['species'].nunique().reset_index()
puntos_diversos = diversidad_por_ubicacion[diversidad_por_ubicacion['species'] > 100]

# Encontrar los meses con mayor diversidad en cada ubicación
diversidad_mensual = df_final.groupby(['decimalLongitude', 'decimalLatitude', 'month'])['species'].nunique().reset_index()
idx = diversidad_mensual.groupby(['decimalLongitude', 'decimalLatitude'])['species'].idxmax()
meses_pico = diversidad_mensual.loc[idx]

# Combinar con los puntos diversos
puntos_diversos_con_mes = puntos_diversos.merge(
    meses_pico[['decimalLongitude', 'decimalLatitude', 'month', 'species']],
    on=['decimalLongitude', 'decimalLatitude'],
    suffixes=('_total', '_pico')
)

# Crear mapa interactivo con folium
# Centrar el mapa en el punto promedio de todos los puntos diversos
mapa_center = [puntos_diversos_con_mes['decimalLatitude'].mean(),
               puntos_diversos_con_mes['decimalLongitude'].mean()]

m = folium.Map(location=mapa_center, zoom_start=10, tiles='OpenStreetMap')

# Diccionario para mapear números de mes a nombres
nombres_meses = {
    1: 'Enero', 2: 'Febrero', 3: 'Marzo', 4: 'Abril',
    5: 'Mayo', 6: 'Junio', 7: 'Julio', 8: 'Agosto',
    9: 'Septiembre', 10: 'Octubre', 11: 'Noviembre', 12: 'Diciembre'
}

# Añadir marcadores para cada punto diverso
for idx, row in puntos_diversos_con_mes.iterrows():
    # Determinar color según el mes de máxima diversidad
    # Usamos un esquema de colores diferente para cada mes
    colores = ['red', 'blue', 'green', 'purple', 'orange', 'darkred',
               'lightred', 'beige', 'darkblue', 'darkgreen', 'cadetblue', 'pink']

    color_marcador = colores[int(row['month']) - 1]  # -1 porque los meses van de 1 a 12

    # Crear popup con información
    popup_text = f"""
    <b>Ubicación:</b> {row['decimalLatitude']:.4f}, {row['decimalLongitude']:.4f}<br>
    <b>Total especies:</b> {row['species_total']}<br>
    <b>Mejor mes:</b> {nombres_meses[row['month']]}<br>
    <b>Especies en mes pico:</b> {row['species_pico']}
    """

    # Añadir marcador al mapa
    folium.Marker(
        location=[row['decimalLatitude'], row['decimalLongitude']],
        popup=popup_text,
        tooltip=f"{nombres_meses[row['month']]} - {row['species_total']} especies",
        icon=folium.Icon(color=color_marcador, icon='info-sign')
    ).add_to(m)

# Añadir leyenda de colores
legend_html = '''
     <div style="position: fixed;
                 bottom: 50px; left: 50px; width: 250px; height: 220px;
                 border:2px solid grey; z-index:9999; font-size:14px;
                 background-color:white;
                 padding: 10px;">
         <b>Leyenda - Mes de máxima diversidad</b><br>
         <i style="background: red; width: 20px; height: 20px; display: inline-block;"></i> Enero<br>
         <i style="background: blue; width: 20px; height: 20px; display: inline-block;"></i> Febrero<br>
         <i style="background: green; width: 20px; height: 20px; display: inline-block;"></i> Marzo<br>
         <i style="background: purple; width: 20px; height: 20px; display: inline-block;"></i> Abril<br>
         <i style="background: orange; width: 20px; height: 20px; display: inline-block;"></i> Mayo<br>
         <i style="background: darkred; width: 20px; height: 20px; display: inline-block;"></i> Junio<br>
         <i style="background: lightred; width: 20px; height: 20px; display: inline-block;"></i> Julio<br>
         <i style="background: beige; width: 20px; height: 20px; display: inline-block;"></i> Agosto<br>
         <i style="background: darkblue; width: 20px; height: 20px; display: inline-block;"></i> Septiembre<br>
         <i style="background: darkgreen; width: 20px; height: 20px; display: inline-block;"></i> Octubre<br>
         <i style="background: cadetblue; width: 20px; height: 20px; display: inline-block;"></i> Noviembre<br>
         <i style="background: pink; width: 20px; height: 20px; display: inline-block;"></i> Diciembre
     </div>
'''

m.get_root().html.add_child(folium.Element(legend_html))

# Guardar y mostrar el mapa
m.save('mapa_diversidad_especies.html')
display(m)

print("Mapa guardado como 'mapa_diversidad_especies.html'")
print("Abre este archivo en tu navegador para ver el mapa interactivo")
print("\n=== ANÁLISIS COMPLETADO ===")

"""# **Modelo Predictivo para Especies Predominantes a partir de Clústers**"""

# 11. Modelo predictivo para especies predominantes
print("\n=== MODELO PREDICTIVO ===")

# Preparar datos para el modelo
df_modelo = df_final.copy()
df_modelo['es_top_especie'] = df_modelo['species'].isin(top_10_especies).astype(int)

# One-hot encoding para variables categóricas
X = pd.get_dummies(df_modelo[['month', 'locality', 'cluster']])
y = df_modelo['es_top_especie']

# Entrenar modelo
modelo = RandomForestClassifier(n_estimators=100, random_state=42)
modelo.fit(X, y)

# Importancia de características
importancia = pd.DataFrame({
    'caracteristica': X.columns,
    'importancia': modelo.feature_importances_
}).sort_values('importancia', ascending=False)

print("Características más importantes para predecir especies predominantes:")
print(importancia.head(10))

# Visualización de importancia
plt.figure(figsize=(10, 6))
plt.barh(importancia['caracteristica'].head(10), importancia['importancia'].head(10))
plt.title('Características Más Importantes para Predecir Especies Predominantes')
plt.tight_layout()
plt.show()

"""# **Modelo de Predicción por Mes**"""

# 12. ANÁLISIS DETALLADO POR MES - ESPECIES MÁS OBSERVADAS POR MES
print("\n=== ANÁLISIS POR MES - ESPECIES MÁS OBSERVADAS ===")

# Crear una tabla de contingencia de especies por mes
especies_por_mes = pd.crosstab(df_final['month'], df_final['species'])

# Para cada mes, obtener las 5 especies más observadas
top_especies_por_mes = {}
for mes in range(1, 13):
    if mes in especies_por_mes.index:
        top_5 = especies_por_mes.loc[mes].nlargest(5)
        top_especies_por_mes[mes] = top_5
        print(f"Mes {mes}: {', '.join([f'{esp} ({cnt})' for esp, cnt in top_5.items()])}")

# Visualización: Heatmap de especies por mes (top 15 especies)
top_15_especies = df_final['species'].value_counts().head(15).index
especies_por_mes_top15 = pd.crosstab(df_final['month'], df_final['species'])[top_15_especies]

plt.figure(figsize=(14, 10))
sns.heatmap(especies_por_mes_top15, cmap='YlOrRd', annot=True, fmt='d', cbar_kws={'label': 'Número de registros'})
plt.title('Distribución Mensual de las 15 Especies Más Comunes en Calarcá')
plt.xlabel('Especies')
plt.ylabel('Mes')
plt.tight_layout()
plt.show()

# 13. ANÁLISIS DE DIVERSIDAD POR MES
print("\n=== DIVERSIDAD DE ESPECIES POR MES ===")
diversidad_por_mes = df_final.groupby('month')['species'].nunique()

plt.figure(figsize=(12, 6))
diversidad_por_mes.plot(kind='bar', color='lightseagreen')
plt.title('Número de Especies Únicas Observadas por Mes en Calarcá')
plt.xlabel('Mes')
plt.ylabel('Número de Especies Únicas')
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

print("Diversidad por mes (número de especies únicas):")
for mes, diversidad in diversidad_por_mes.items():
    print(f"Mes {mes}: {diversidad} especies")

# 14. ANÁLISIS DE ESTACIONALIDAD DE ESPECIES ESPECÍFICAS
print("\n=== ANÁLISIS DE ESTACIONALIDAD DE ESPECIES ESPECÍFICAS ===")

# Seleccionar algunas especies interesantes para analizar su estacionalidad
especies_interes = top_especies.head(5).index.tolist()  # Las 5 especies más comunes

plt.figure(figsize=(14, 10))
for i, especie in enumerate(especies_interes, 1):
    plt.subplot(3, 2, i)
    datos_especie = df_final[df_final['species'] == especie]
    registros_por_mes = datos_especie['month'].value_counts().sort_index()

    # Completar meses sin registros con cero
    for mes in range(1, 13):
        if mes not in registros_por_mes.index:
            registros_por_mes[mes] = 0

    registros_por_mes = registros_por_mes.sort_index()
    registros_por_mes.plot(kind='bar', color='steelblue')
    plt.title(f'Registros de {especie} por Mes')
    plt.xlabel('Mes')
    plt.ylabel('Número de Registros')
    plt.xticks(rotation=0)

plt.tight_layout()
plt.show()

# 15. MODELO DE PREDICCIÓN POR MES
print("\n=== MODELO DE PREDICCIÓN POR MES ===")

# Preparar datos para el modelo de predicción mensual
df_modelo_mes = df_final.copy()

# Crear variables dummy para las especies
especies_dummies = pd.get_dummies(df_modelo_mes['species'], prefix='esp')

# Combinar con el dataframe original
df_modelo_mes = pd.concat([df_modelo_mes, especies_dummies], axis=1)

# Agrupar por mes y sumar las observaciones de cada especie
datos_por_mes = df_modelo_mes.groupby('month').sum(numeric_only=True)

# Seleccionar solo las columnas de especies
especies_columns = [col for col in datos_por_mes.columns if col.startswith('esp_')]
datos_por_mes = datos_por_mes[especies_columns]

# Normalizar los datos (porcentaje de cada especie por mes)
datos_por_mes_normalizados = datos_por_mes.div(datos_por_mes.sum(axis=1), axis=0) * 100

# Visualizar la composición de especies por mes
plt.figure(figsize=(16, 10))
datos_por_mes_normalizados.plot(kind='bar', stacked=True, cmap='tab20', figsize=(16, 10))
plt.title('Composición de Especies por Mes en Calarcá (%)')
plt.xlabel('Mes')
plt.ylabel('Porcentaje de Registros')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# 16. IDENTIFICACIÓN DE ESPECIES ESTACIONALES
print("\n=== ESPECIES CON PATRONES ESTACIONALES MARCADOS ===")

# Calcular la estacionalidad de cada especie (variación entre meses)
estacionalidad_especies = datos_por_mes_normalizados.std() / datos_por_mes_normalizados.mean()

# Especies con mayor estacionalidad (mayor variación entre meses)
especies_estacionales = estacionalidad_especies.sort_values(ascending=False).head(10)

print("Especies con patrones estacionales más marcados:")
for especie, valor in especies_estacionales.items():
    nombre_especie = especie.replace('esp_', '')
    print(f"{nombre_especie}: {valor:.2f}")

# Visualizar las especies más estacionales
especies_mas_estacionales = especies_estacionales.index.tolist()
datos_estacionales = datos_por_mes_normalizados[especies_mas_estacionales[:5]]  # Top 5

plt.figure(figsize=(12, 6))
for especie in datos_estacionales.columns:
    plt.plot(datos_estacionales.index, datos_estacionales[especie], marker='o', label=especie.replace('esp_', ''))

plt.title('Especies con Patrones Estacionales Más Marcados')
plt.xlabel('Mes')
plt.ylabel('Porcentaje de Registros')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# Paso 12: Mapa de puntos con mayor diversidad de especies
import cartopy.feature as cfeature
import cartopy.crs as ccrs
# Filtrar ubicaciones con más de 100 especies únicas
diversidad_por_ubicacion = df_final.groupby(['decimalLongitude', 'decimalLatitude'])['species'].nunique().reset_index()
puntos_diversos = diversidad_por_ubicacion[diversidad_por_ubicacion['species'] > 100]

# Encontrar los meses con mayor diversidad en cada ubicación
diversidad_mensual = df_final.groupby(['decimalLongitude', 'decimalLatitude', 'month'])['species'].nunique().reset_index()
idx = diversidad_mensual.groupby(['decimalLongitude', 'decimalLatitude'])['species'].idxmax()
meses_pico = diversidad_mensual.loc[idx]

# Combinar con los puntos diversos
puntos_diversos_con_mes = puntos_diversos.merge(
    meses_pico[['decimalLongitude', 'decimalLatitude', 'month', 'species']],
    on=['decimalLongitude', 'decimalLatitude'],
    suffixes=('_total', '_pico')
)

# Crear el mapa
plt.figure(figsize=(15, 10))
ax = plt.axes(projection=ccrs.PlateCarree())

# Añadir características del mapa
ax.add_feature(cfeature.COASTLINE)
ax.add_feature(cfeature.BORDERS, linestyle=':')
ax.add_feature(cfeature.LAND, color='lightgray')
ax.add_feature(cfeature.OCEAN, color='lightblue')
ax.gridlines(draw_labels=True)

# Crear scatter plot con colores según el mes de máxima diversidad
scatter = ax.scatter(
    puntos_diversos_con_mes['decimalLongitude'],
    puntos_diversos_con_mes['decimalLatitude'],
    c=puntos_diversos_con_mes['month'],
    cmap='viridis',
    s=100,
    alpha=0.7,
    transform=ccrs.PlateCarree()
)

# Añadir barra de color
cbar = plt.colorbar(scatter, orientation='vertical', pad=0.05)
cbar.set_label('Mes de máxima diversidad')

# Añadir título
plt.title('Puntos con más de 100 especies registradas\n(Color indica el mes de máxima diversidad)', fontsize=14)

# Mostrar el mapa
plt.show()

# Información adicional: Top 5 meses con mayor diversidad global
diversidad_global_mensual = df_final.groupby('month')['species'].nunique().sort_values(ascending=False)
print("\nTop 5 meses con mayor diversidad de especies (global):")
print(diversidad_global_mensual.head())

"""#**Medición del Desempeño del Modelo**"""

# EVALUACIÓN DEL MODELO DE CLUSTERING
print("\n" + "="*60)
print("EVALUACIÓN DEL MODELO DE CLUSTERING")
print("="*60)

from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.preprocessing import StandardScaler

# Preparar los datos para evaluación
coordenadas = df_final[['decimalLatitude', 'decimalLongitude']].values

# Escalar los datos para una mejor evaluación (importante para métricas de distancia)
scaler = StandardScaler()
coordenadas_escaladas = scaler.fit_transform(coordenadas)

# Obtener las etiquetas de cluster asignadas por K-Means
etiquetas_clusters = df_final['cluster'].values

# Calcular métricas de evaluación de clustering
print("\n--- MÉTRICAS DE EVALUACIÓN DE CLUSTERING ---")

# 1. Silhouette Score
# Mide qué tan bien separados están los clusters (valores entre -1 y 1)
# Valores más altos indican clusters mejor definidos
silhouette_avg = silhouette_score(coordenadas_escaladas, etiquetas_clusters)
print(f"Silhouette Score: {silhouette_avg:.4f}")

# Interpretación del Silhouette Score
if silhouette_avg > 0.7:
    print("  → Los clusters están bien separados y definidos")
elif silhouette_avg > 0.5:
    print("  → Los clusters están razonablemente separados")
elif silhouette_avg > 0.3:
    print("  → Los clusters tienen una separación débil")
else:
    print("  → Los clusters pueden no estar bien separados")

# 2. Calinski-Harabasz Index
# Mide la relación entre la dispersión entre clusters y la dispersión dentro de los clusters
# Valores más altos indican clusters mejor definidos
calinski_harabasz = calinski_harabasz_score(coordenadas_escaladas, etiquetas_clusters)
print(f"Calinski-Harabasz Index: {calinski_harabasz:.4f}")

# 3. Davies-Bouldin Index
# Mide la similitud promedio entre clusters (cuanto más bajo, mejor)
# Valores más bajos indican clusters mejor separados
davies_bouldin = davies_bouldin_score(coordenadas_escaladas, etiquetas_clusters)
print(f"Davies-Bouldin Index: {davies_bouldin:.4f}")

# Interpretación del Davies-Bouldin Index
if davies_bouldin < 0.5:
    print("  → Los clusters están muy bien separados")
elif davies_bouldin < 1.0:
    print("  → Los clusters están razonablemente separados")
else:
    print("  → Los clusters podrían estar superpuestos")

# Evaluación adicional: Análisis de la inercia (suma de distancias al cuadrado)
inercia = kmeans.inertia_
print(f"Inercia: {inercia:.4f}")

# Visualización de las métricas para diferentes valores de k (si es necesario)
print("\n--- EVALUACIÓN PARA DIFERENTES VALORES DE K ---")

# Probaremos con diferentes valores de k para encontrar el óptimo
valores_k = range(2, 11)
silhouette_scores = []
calinski_scores = []
davies_scores = []
inercias = []

for k in valores_k:
    kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)
    etiquetas_temp = kmeans_temp.fit_predict(coordenadas_escaladas)

    silhouette_scores.append(silhouette_score(coordenadas_escaladas, etiquetas_temp))
    calinski_scores.append(calinski_harabasz_score(coordenadas_escaladas, etiquetas_temp))
    davies_scores.append(davies_bouldin_score(coordenadas_escaladas, etiquetas_temp))
    inercias.append(kmeans_temp.inertia_)

# Visualización de las métricas
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))

# Silhouette Score
ax1.plot(valores_k, silhouette_scores, 'bo-')
ax1.set_xlabel('Número de clusters (k)')
ax1.set_ylabel('Silhouette Score')
ax1.set_title('Silhouette Score para diferentes valores de k')
ax1.grid(True, alpha=0.3)

# Calinski-Harabasz Index
ax2.plot(valores_k, calinski_scores, 'ro-')
ax2.set_xlabel('Número de clusters (k)')
ax2.set_ylabel('Calinski-Harabasz Index')
ax2.set_title('Calinski-Harabasz Index para diferentes valores de k')
ax2.grid(True, alpha=0.3)

# Davies-Bouldin Index
ax3.plot(valores_k, davies_scores, 'go-')
ax3.set_xlabel('Número de clusters (k)')
ax3.set_ylabel('Davies-Bouldin Index')
ax3.set_title('Davies-Bouldin Index para diferentes valores de k')
ax3.grid(True, alpha=0.3)

# Método del codo (Inercia)
ax4.plot(valores_k, inercias, 'mo-')
ax4.set_xlabel('Número de clusters (k)')
ax4.set_ylabel('Inercia')
ax4.set_title('Método del Codo para diferentes valores de k')
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Evaluación cualitativa: Análisis de la interpretabilidad de los clusters
print("\n--- EVALUACIÓN CUALITATIVA DE LOS CLUSTERS ---")

# Para cada cluster, analizar su composición en términos de localidades y especies
for cluster_id in sorted(df_final['cluster'].unique()):
    cluster_data = df_final[df_final['cluster'] == cluster_id]

    print(f"\nCluster {cluster_id} ({len(cluster_data)} registros):")

    # Localidades principales en este cluster
    top_localidades = cluster_data['locality'].value_counts().head(3)
    print(f"  Localidades principales: {', '.join([f'{loc} ({cnt})' for loc, cnt in top_localidades.items()])}")

    # Especies principales en este cluster
    top_especies = cluster_data['species'].value_counts().head(3)
    print(f"  Especies principales: {', '.join([f'{esp} ({cnt})' for esp, cnt in top_especies.items()])}")

    # Extensión geográfica del cluster
    lat_min, lat_max = cluster_data['decimalLatitude'].min(), cluster_data['decimalLatitude'].max()
    lon_min, lon_max = cluster_data['decimalLongitude'].min(), cluster_data['decimalLongitude'].max()
    print(f"  Extensión geográfica: Lat {lat_min:.4f}-{lat_max:.4f}, Lon {lon_min:.4f}-{lon_max:.4f}")

# Conclusión general de la evaluación
print("\n" + "="*60)
print("CONCLUSIÓN DE LA EVALUACIÓN DEL CLUSTERING")
print("="*60)

# You need to determine k_optimo based on the elbow method or other metrics visually.
# As a placeholder, I'll use the k used in the previous clustering cell (k=3).
# In a real scenario, you would choose k_optimo from the plots.
k_optimo = 3

print(f"Basado en las métricas calculadas, el clustering con k={k_optimo} clusters:")
print(f"- Silhouette Score: {silhouette_avg:.4f} (valores > 0.5 indican clusters razonablemente separados)")
print(f"- Calinski-Harabasz Index: {calinski_harabasz:.4f} (valores más altos indican clusters mejor definidos)")
print(f"- Davies-Bouldin Index: {davies_bouldin:.4f} (valores más bajos indican clusters mejor separados)")

if silhouette_avg > 0.5 and davies_bouldin < 1.0:
    print("\n→ El modelo de clustering muestra un buen desempeño con clusters bien definidos.")
elif silhouette_avg > 0.3 and davies_bouldin < 1.5:
    print("\n→ El modelo de clustering tiene un desempeño aceptable, pero podría mejorar.")
else:
    print("\n→ El modelo de clustering podría no estar capturando adecuadamente la estructura de los datos.")

"""# **Versiones de Librerías Utilizadas**"""

# Verificar versiones de librerías principales utilizadas
print("=== VERSIONES DE LIBRERÍAS PRINCIPALES ===")

try:
    import pandas as pd
    print(f"Pandas: {pd.__version__}")
except ImportError:
    print("Pandas no está instalado")

try:
    import numpy as np
    print(f"NumPy: {np.__version__}")
except ImportError:
    print("NumPy no está instalado")

try:
    import matplotlib as mpl
    print(f"Matplotlib: {mpl.__version__}")
except ImportError:
    print("Matplotlib no está instalado")

try:
    import seaborn as sns
    print(f"Seaborn: {sns.__version__}")
except ImportError:
    print("Seaborn no está instalado")

try:
    import sklearn
    print(f"Scikit-learn: {sklearn.__version__}")
except ImportError:
    print("Scikit-learn no está instalado")

try:
    import statsmodels as sm
    print(f"Statsmodels: {sm.__version__}")
except ImportError:
    print("Statsmodels no está instalado")

try:
    import folium
    print(f"Folium: {folium.__version__}")
except ImportError:
    print("Folium no está instalado")

try:
    import plotly
    print(f"Plotly: {plotly.__version__}")
except ImportError:
    print("Plotly no está instalado")

    # Información del sistema y entorno
print("=== INFORMACIÓN DEL SISTEMA ===")
import platform
print(f"Plataforma: {platform.platform()}")
print(f"Versión de Python: {platform.python_version()}")

# Información de Google Colab
try:
    import google.colab
    print("Entorno: Google Colab")

    # Obtener información específica de Colab
    print("=== INFORMACIÓN DE GOOGLE COLAB ===")
    !python --version
    !cat /etc/os-release | grep PRETTY_NAME
except:
    print("No se está ejecutando en Google Colab")

def obtener_info_entorno():
    """Función para obtener información completa del entorno"""
    print("=" * 50)
    print("INFORMACIÓN DEL ENTORNO DE EJECUCIÓN")
    print("=" * 50)

    # Información del sistema
    import platform
    print(f"\nSistema: {platform.platform()}")
    print(f"Python: {platform.python_version()}")

    # Verificar si estamos en Colab
    try:
        import google.colab
        print("Entorno: Google Colab")
    except:
        print("Entorno: Local u otro")

    # Librerías principales
    print("\n--- VERSIONES DE LIBRERÍAS PRINCIPALES ---")
    librerias = {
        'pandas': 'pd',
        'numpy': 'np',
        'matplotlib': 'mpl',
        'seaborn': 'sns',
        'sklearn': 'sklearn',
        'statsmodels': 'sm',
        'folium': 'folium',
        'plotly': 'plotly'
    }

    for lib, alias in librerias.items():
        try:
            modulo = __import__(lib)
            if hasattr(modulo, '__version__'):
                print(f"{lib}: {modulo.__version__}")
            else:
                print(f"{lib}: instalada (versión no disponible)")
        except ImportError:
            print(f"{lib}: no instalada")

    # Espacio en disco y memoria (útil para Colab)
    print("\n--- RECURSOS DEL SISTEMA ---")
    !df -h / | grep -v Filesystem
    print("\nMemoria disponible:")
    !free -h

# Ejecutar la función
obtener_info_entorno()